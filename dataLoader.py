
import pickle
import pandas as pd
import os

from torch.utils.data import DataLoader, Dataset

# Dataset class where every element is (x, y) where x
# is a tokenized list of words and y is the label.
class TextDataset(Dataset):

    def __init__(self, dataset, tokenizer):
        self.original_dataset = dataset
        self.tokenizer = tokenizer

    def __len__(self):
        return len(self.original_dataset)

    def __getitem__(self, index):

        SEP_TOKEN = '[SEP]'
        CLS_TOKEN = '[CLS]'

        original_data = self.original_dataset.iloc[index]
        text = original_data[0]
        label = int(original_data[1])

        # Tokenize text, convert to ids
        tokens = CLS_TOKEN + text + SEP_TOKEN
        tokens = tokenizer.encode(tokens)
        input_ids = tokens.ids
        input_ids = input_ids[:MAX_SEQ_LENGTH]

        padding_length = MAX_SEQ_LENGTH - len(input_ids)
        input_length = len(input_ids)
        input_ids = input_ids + [0] * padding_length

        ## (data, input_len, targets)
        return torch.tensor(input_ids, dtype=torch.long), \
                torch.tensor(input_length, dtype=torch.long), \
                 torch.tensor(label, dtype=torch.long)

def stackTraceDataloader(event, tokenizer, train_split=0.8, batch_size=64):

    dataset = pickle.load(open('stack_{}.pickle'.format(event), 'rb'))
    dataset = pd.DataFrame(dataset)
    dataset = dataset.sample(frac=1)

    train_ds = dataset.iloc[:int(train_split * len(dataset.index))]
    val_ds = dataset.iloc[int(train_split * len(dataset.index)):]

    train_dl = DataLoader(TextDataset(train_ds, tokenizer), batch_size=batch_size, shuffle=True)
    val_dl = DataLoader(TextDataset(val_ds, tokenizer), batch_size=batch_size, shuffle=True)

    return train_dl, val_dl
