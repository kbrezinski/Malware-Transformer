
from easydict import EasyDict as edict

## Init
__C = edict()
cfg = __C

## seed Value
__C.SEED = 2021

## transformer params
__C.EMBED_SIZE = 50 # number of embedding layers
__C.NHID = 2 # number of nn.TransformerEncoder layers
__C.NLAYERS = 2 # number of nn.TransformerEncoderLayer layers
__C.NHEAD = 2 # number of heads in multi-head attn layers

## model training params
__C.MAXEPOCHS = 10 # number of epochs
__C.DROP = 0.1 # dropout probability
__C.CLIPGRAD = 0.5 ## gradient clipping norm
__C.LR = 1e-3   # init lr
__C.GAMMA = 0.9 # decrease in lr per epoch

## number of tokens to consider
__C.NUMTOKENS = 2_000
__C.MAXLEN = 100

## trainer params
__C.LOGINTER = 200 # loggin interval
__C.GPUID = [0] # gpu idea
